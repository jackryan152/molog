#!/usr/bin/env python
# -*- coding: utf-8 -*-
#
#       untitled.py
#       
#       Copyright 2011 Jelle <jelle@indigo>
#       
#       This program is free software; you can redistribute it and/or modify
#       it under the terms of the GNU General Public License as published by
#       the Free Software Foundation; either version 2 of the License, or
#       (at your option) any later version.
#       
#       This program is distributed in the hope that it will be useful,
#       but WITHOUT ANY WARRANTY; without even the implied warranty of
#       MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#       GNU General Public License for more details.
#       
#       You should have received a copy of the GNU General Public License
#       along with this program; if not, write to the Free Software
#       Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston,
#       MA 02110-1301, USA.
#       
#       

import logging
import daemon
import os
import sys
import pymongo
import re
import time
import pika
import json
import pyes
import threading
import cherrypy
from datetime import date
from logging.handlers import SysLogHandler
from pymongo.objectid import ObjectId
from pika.adapters import SelectConnection
from optparse import OptionParser
from multiprocessing import Process, Manager, Queue
from configobj import ConfigObj
from time import sleep


__version__='0.1'

class Logger():
	'''Creates a logger class and writes to screen or syslog.'''
	def __init__(self, loglevel='DEBUG'):
		self.loglevel=loglevel
		self.screen_format=logging.Formatter('%(asctime)s %(levelname)s::%(processName)s:%(message)s')
		self.syslog_format=logging.Formatter('NetCrawl %(processName)s %(message)s')
	def get(self,name=None, scrlog=True, txtlog=True):
		'''Returns a logger object to use.'''
		log = logging.getLogger(name)
		log.setLevel(self.loglevel)
		syslog=SysLogHandler(address='/dev/log')
		syslog.setFormatter(self.syslog_format)
		log.addHandler(syslog)	

		if scrlog == True:
			scr_handler = logging.StreamHandler()
			scr_handler.setFormatter(self.screen_format)
			log.addHandler(scr_handler)
		return log
class RegexHandler():
	'''Class used to manipulate the regexes stored in MongoDB'''
	def __init__(self,db,logger):
		self.db=db
		self.logger=logger
		self.host_regexes=Manager().dict()
		self.default_regexes=Manager().dict()
	def add(self,data=None):
		'''Adds a regex.'''
		self.db.regexes.insert(data)
	def update(self,id,regex):
		'''Updates a regex to a new value.'''
		pass
class MatchWorker(Process):
	'''Matchworker is a worker process which consumes the queue.  It can run in parallel.'''
	def __init__(self,broker_host,broker_queue,elastic_search,mongo_db,priority_map,logger,block):
		Process.__init__(self)
		self.broker=broker_host
		self.queue=broker_queue
		self.elastic_search=elastic_search
		self.mongo_db=mongo_db
		self.priority_map=priority_map
		self.logger=logger
		self.block=block
				
		self.daemon=True
		self.start()
	def run(self):
		self.logger.info('Started')
		#Setup Broker connection
		self.parameters = pika.ConnectionParameters(self.broker)
		self.connection = SelectConnection(self.parameters,self.__on_connected)	
		try:
			self.connection.ioloop.start()
		except KeyboardInterrupt:
			self.connection.close()
			self.connection.ioloop.start()
	def __on_connected(self,connection):
		self.logger.info('Connecting to broker.')
		connection.channel(self.__on_channel_open)
	def __on_channel_open(self,new_channel):
		self.channel = new_channel
		self.__initialize()
		self.channel.basic_consume(self.processData, queue = self.queue)
		self.channel.basic_qos(prefetch_count=1)
	def __initialize(self):
		self.logger.debug('Creating exchanges, queues and bindings on broker.')
		self.channel.exchange_declare(exchange=self.queue,type='fanout',durable=True)
		self.channel.queue_declare(queue=self.queue,durable=True)
	def processData(self,ch, method, properties, body):
		'''Broker connection callback which does all the heavy lifting on the incoming data.'''
		try:
			data = json.loads(body)
		except Exception as err:
			self.logger.warn('Garbage reveived from broker, purging. Reason: %s'%(err))
			self.channel.basic_ack(delivery_tag=method.delivery_tag)
		else:
			if self.ignoreLog(data) == False:
				try:
					feedback=self.writeElastic(data)
					self.writeMongo(host=data['@source_host'], id=feedback['_id'], level=self.priority_map(priority = data['@fields']['priority'][0]) )
					self.updateMonitoring(host=data['@source_host'],message=data['@message'])
				except Exception as err:
					self.logger.warn('I could not process record entirely. Resubmitted to queue. Reason: %s'%(err))
				else:
					self.writeElastic(data)
					self.channel.basic_ack(delivery_tag=method.delivery_tag)
			else:
				self.writeElastic(data)
				self.channel.basic_ack(delivery_tag=method.delivery_tag)			
	def ignoreLog(self,document):
		'''Applies all defined regexes on the document to see whether we can ignore it'''
		for regex in self.mongo_db.regexes.find({}).sort('order'):
			if re.match(regex['type'],document['@type']):
				if len(regex['regexes']) > 0:
					flag=True
					for field in regex['regexes']:
						if document['@fields'].has_key(field):
							for data in document['@fields'][field]:
								if not re.match(regex['regexes'][field],data):
									flag = False
			if flag == True:
				return True
		return False
	def writeElastic(self,data):
		'''Writes the incoming data to Elasticsearch.'''
		return self.elastic_search.insert(data)
	def writeMongo(self,host=None,id=None,level=None):
		'''Writes the references towards the Elasticsearch object in the DB'''
		self.mongo_db.results.insert({'host':host,'level':level,'es_ref':id})
	def updateMonitoring(self,host=None,message=None):
		'''Sends an update message to monitoring indicating the total warnings/criticals of a host have changed.'''
		self.logger.debug("Send an update to monitoring for host %s. %s warning %s critical"%(host,self.mongo_db.results.find({'host':host,'level':'warning'}).count(),self.mongo_db.results.find({'host':host,'level':'critical'}).count()))
class MongoDBConnection():
	'''Creates a MongoDB connection object.'''
	def __init__(self,host,logger,es_lookup=None):
		self.connection=pymongo.Connection(host)
		self.db = self.connection.molog
		self.es_lookup=es_lookup
		self.logger=logger
	def __checkIntegrity(self):
		pass
	def queryRegex(self,id=None,tags=None):
		query={}
		if id == None:
			query = self.__buildTagQuery(tags=tags)
			list=[]
			for regex in self.db.regexes.find(query).sort('order'):
				regex = self.__replaceID(regex)
				list.append(regex)				
			return json.dumps(list)
		else:
			return json.dumps(self.__replaceID(data=self.db.regexes.find_one( { '_id' : ObjectId(id) } )))
	def removeRegex(self,id=None,tags=None):
		if id == None:
			query = self.__buildTagQuery(tags=tags)
			try:
				self.db.regexes.remove( query )
			except:
				pass
			else:
				return json.dumps({'status':'ok'})
		else:
			try:
				self.db.regexes.remove( { '_id' : ObjectId(id) } )
			except:
				pass
			else:
				return json.dumps({'status':'ok'})
	def insertRegex(self,document=None):
		if self.__checkRegexIntegrity(document=document) == True:
			self.db.regexes.insert(json.loads(document))
			return json.dumps({"status":"ok"})
		else:
			return json.dumps({"status":"nok","message":"document not valid"})
	def updateRegex(self,id=None,document=None):
		if self.__checkRegexIntegrity(document=document,partial=True) == True:
			self.db.regexes.update({'_id':ObjectId(id)},{'$set':json.loads(document)})
			return json.dumps({"status":"ok"})
		else:
			return json.dumps({"status":"nok","message":"document not valid"})
	def queryHost(self,id=None,hostname=None,level=None):
		if id == None:
			query = self.__buildHostQuery(hostname=hostname,level=level)
			list=[]
			for result in self.db.results.find(query):
				result = self.__replaceID(result)
				message = self.es_lookup(id = result['es_ref'] )
				result.update( {'message':message } )
				list.append(result)
			return json.dumps(list)				
	def __replaceID(self,data=None):
		if data == None or data == '':
			return []
		else:
			data['id'] = str(ObjectId(data['_id']))
			del data['_id']
			return data
	def __convertList(self,list=None):
		if list == None:
			return []
		else:
			return list.split(',')		
	def __buildTagQuery(self,tags=None):
		if tags == None:
			return {}
		else:
			tags = self.__convertList(list=tags)
			return {'tags':{ '$all': tags }}
	def __checkRegexIntegrity(self,document={},partial=False):
		white_list = { 'regexes': dict, 'type':unicode , 'tags':list, 'order':unicode }
		try:
			document = json.loads(document)
			for element in document.keys():
				if element not in white_list.keys():
					raise Exception("%s invalid data in Regex document."%element)
				if type(document[element]) is not white_list[element]:
					raise Exception("%s is invalid type."%element)			
			if partial == False:
				for key in white_list:
					document[key]
			return True
		except Exception as err:
			print err
			self.logger.warning ("Invalid Regex document. Reason: %s"%err)
			return False
	def __buildHostQuery(self,hostname=None,level=None):
		query = {}
		if hostname != None:
			query.update({'host':hostname})
		if level != None:
			query.update({'level':level})
		return query		
class ElasticSearch():
	'''Creates an ElasticSearch connection object'''
	def __init__(self,host):
		self.conn = pyes.ES([host])
	def insert(self,data):
		'''Inserts a document in ES with the right index'''
		return self.conn.index(data,"logstash-%s.%s.%s"%(date.today().year, date.today().month, date.today().day),data['@type'])
	def messageMap(self,id):
		q = pyes.query.IdsQuery(None,id)
		result= self.conn.search(query=q)['hits']['hits'][0]['_source']['@fields']
		return ( result['SYSLOGPROG'][0]+': '+result['message'][0] )		
class WebServer(threading.Thread):
	def __init__(self,host,port,ssl="off",ssl_certificate=None,ssl_private_key=None,rest_functions=None,enable_logging=True,logger=None,blockcallback=None):
		threading.Thread.__init__(self)
		self.host=host
		self.port=port
		self.ssl=ssl
		self.ssl_certificate=ssl_certificate
		self.ssl_private_key=ssl_private_key
		self.rest_functions=rest_functions
		self.enable_logging=enable_logging
		self.logger=logger
		self.loop=blockcallback
		self.daemon=True
		self.start()		
	def run(self):
		self.logger.info("WebServer thread started on %s:%s"%(self.host,self.port))
		config={'global': {'server.socket_host': self.host},
			'/': {'request.dispatch': cherrypy.dispatch.MethodDispatcher()}
			}
		cherrypy.config.update(	
								{ 
								'global': 
									{
									'server.socket_port': int(self.port),
									'server.socket_host': self.host,
									'tools.sessions.on': False,
									'log.screen': False
									}
								}
								)
						
		#check if we need to run over https or not
		if self.ssl == "on":
			cherrypy.config.update(
									{
									'server.ssl_certificate': self.ssl_certificate,
									'server.ssl_private_key': self.ssl_private_key
									}
								  )	
		
		cp_app = cherrypy.tree.mount(self.rest_functions,'/',config=config)
		
		if self.enable_logging == True:
			cp_app.log.access_log_format = '%(h)s %(l)s %(u)s "%(r)s" %(s)s %(b)s "%(f)s" "%(a)s"'
			cp_app.log.access_log = self.logger
			cp_app.log.error_log = self.logger
		cherrypy.engine.start()
		while self.loop() == True:
			time.sleep(0.1)
		cherrypy.engine.exit()
		self.logger.info("WebServer thread stopped.")
class RestRegex():
	exposed=True
	def __init__(self,db=None):
		self.db=db
	def GET(self,*args,**kwargs):
		if len(args) == 0:
			return self.db.queryRegex(tags=kwargs.get('tags',None))
		else:
			return self.db.queryRegex(id=args[0])
	def DELETE(self,*args,**kwargs):
		if len(args) == 0:
			return self.db.removeRegex(tags=kwargs.get('tags',None))
		else:
			return self.db.removeRegex(id=args[0])
	def POST(self,*args,**kwargs):
		if len(args) == 0:
			#insert a regex
			return self.db.insertRegex(document = cherrypy.request.body.read() )
		else:
			#update an existing regex
			return self.db.updateRegex(id = args[0], document = cherrypy.request.body.read() )		
class RestHost():
	exposed=True
	def __init__(self,db=None):
		self.db=db
	def GET(self,*args,**kwargs):
		if len(args) == 0:
			return self.db.queryHost(hostname=kwargs.get('host',None),level=kwargs.get('level',None))
class RestTotals():
	exposed=True	
	def __init__(self,db=None):
		pass
	def GET(self,*args,**kwargs):
		pass
class RestFunctions():
	exposed=True	
	def __init__(self,mongo_db=None):
		self.mongo=mongo_db
		self.regex = RestRegex(db=self.mongo)
		self.host = RestHost(db=self.mongo)
		self.totals = RestTotals(db=self.mongo)
class Server():
	'''Server class handling process control, startup & shutdown'''
	def __init__(self,config):
		self.cfgfile=config
		self.config=None
		self.block=True
	def __loadConfig(self,config=None):
		try:
			return ConfigObj(config)
		except Exception as err:
			sys.stderr.write('There appears to be an error in your configfile:\n')
			sys.stderr.write('\t'+ str(type(err))+" "+str(err) + "\n" )
			os.kill(os.getpid(),signal.SIGKILL)
	def lock(self):
		return self.block
	def doPID(self):
		if self.checkPIDRunning() == False:
			self.writePID()
	def checkPIDRunning(self):
		'''Checks whether the pid file exists and if it does, checks whether a process is running with that pid.
		Returns False when no process is running with that pid otherwise True'''
		if os.path.isfile(self.config['application']['pid']):
			try:
				pid_file = open(self.config['application']['pid'], 'r')
				pid=pid_file.readline()
				pid_file.close()
			except Exception as err:
				sys.stderr.write('I could not open the pid file. Reason: %s\n'%(err))
				sys.exit(1)
		try:
			os.kill(int(pid),0)
		except:
			return False
		else:
			sys.stderr.write('There is already a process running with pid %s\n'%(pid))
			sys.exit(1)				
	def writePID(self):
		try:
			pid = open ( self.config['application']['pid'], 'w' )
			pid.write (str(os.getpid()))
			pid.close()
		except Exception as err:
			sys.stderr.write('I could not write the pid file. Reason: %s\n'%(err))
			sys.exit(1)
	def deletePID(self):
		try:
			os.remove ( self.config['application']['pid'] )
		except:
			pass				
	def start(self):
		#Creating logging object
		logger = Logger()
		self.logger=logger.get(name=self.__class__.__name__)
		self.logger.warning('started')

		#Load config
		self.config = self.__loadConfig(config=self.cfgfile)

		#Write PID
		self.doPID()
		
		#Create RegexLookup
		regex_handler = RegexHandler(	db=MongoDBConnection(	host = self.config['mongodb']['host'],
									logger=self.logger).db,
						logger=self.logger
						)
				
		#Create ElasticSearch object
		elastic_search= ElasticSearch(host=self.config['elasticsearch']['host'])
		
		#Create Workers
		workers=[]
		for worker in range (int(self.config['application']['workers'])):
			workers.append(	MatchWorker(	broker_host=self.config['rabbitmq']['host'],
							broker_queue=self.config['rabbitmq']['queue'],
							mongo_db=MongoDBConnection(	host = self.config['mongodb']['host'],
											logger=self.logger).db,
							elastic_search=elastic_search,
							priority_map=self.__priorityMap,
							logger=self.logger,
							block=self.lock
							)
					)
		rest_functions = RestFunctions	(	mongo_db = MongoDBConnection(	host = self.config['mongodb']['host'],
											es_lookup = elastic_search.messageMap,
											logger=self.logger)
							)
		
		#Start Webserver
		webserver = WebServer	(	host=self.config['API']['host'],
						port=self.config['API']['port'],
						ssl="off",
						ssl_certificate=None,
						ssl_private_key=None,
						rest_functions=rest_functions,
						enable_logging=True,
						logger=self.logger,
						blockcallback=self.lock
						)
						
		while self.lock()==True:
			sleep(0.1)
		
		self.logger.info('Exit')
	def stop(self):
		self.block=False
	def __priorityMap(self,priority):
		'''A basic lookup function mapping priority level to either warning or critical.
		It's a strange place for this function so we might want to move it to some sort of tools class.'''
		if str(priority) in self.config['priority_map']['critical'].split(','):
			return 'critical'
		elif str(priority) in self.config['priority_map']['warning'].split(','):
			return 'warning'
		else:
			return 'ok'
if __name__ == '__main__':
	parser = OptionParser()
	parser.add_option("--config", dest="config", default="main.conf", type="string", help="The location of the config file.")	
	(cli_options,cli_actions)=parser.parse_args()	
	try:
		server=Server(config = cli_options.config)
		if cli_actions[0] == 'start':
			with daemon.DaemonContext():
				server.start()
		elif cli_actions[0] == 'debug':
			server.start()
#	except Exception as err:
#		print str(err)
	except KeyboardInterrupt:
		server.stop()
		server.deletePID()
